{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Explore the data\n",
        "Let's build a multiclass classifier to separate penguins into categories of species. We'll be using palmerpenguins data, which contains size measurements for three penguin species that were observed on three islands in the Palmer Archipelago, Antarctica.\n",
        "In R, the palmerpenguins package, by [Allison Marie Horst and Alison Presmanes Hill and Kristen B Gorman](https://allisonhorst.github.io/palmerpenguins/articles/intro.html), provides the data that's related to these adorable creatures."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Load the required packages and make them available in your current R session\n",
        "suppressPackageStartupMessages({\n",
        "  library(palmerpenguins)\n",
        "  library(tidymodels)\n",
        "})\n",
        "\n",
        "# Take a peek into the data\n",
        "glimpse(penguins)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The data contains the following columns:\n",
        "\n",
        "-   **species:** a factor denoting the penguin species (*Adelie*, *Chinstrap*, or *Gentoo*)\n",
        "\n",
        "-   **island:** a factor denoting the island (in Palmer Archipelago, Antarctica) where observed\n",
        "\n",
        "-   **bill_length_mm (aka culmen_length):** a number denoting length of the dorsal ridge of penguin bill (millimeters)\n",
        "\n",
        "-   **bill_depth_mm (aka culmen_depth):** a number denoting the depth of the penguin bill (millimeters)\n",
        "\n",
        "-   **flipper_length_mm:** an integer denoting penguin flipper length (millimeters)\n",
        "\n",
        "-   **body_mass_g:** an integer denoting penguin body mass (grams)\n",
        "\n",
        "-   **sex:** a factor denoting penguin sex (male, female)\n",
        "\n",
        "-   **year:** an integer denoting the study year (2007, 2008, or 2009)\n",
        "\n",
        "The **species** column containing penguin species *Adelie*, *Chinstrap*, or *Gentoo*, is the label we want to train a model to predict.\n",
        "Let's start by selecting the columns we want to use as features to predicts this label.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Load the skimr column\n",
        "library(skimr)\n",
        "\n",
        "# Select desired columns\n",
        "penguins_select <- penguins %>%\n",
        "  select(c(bill_length_mm, bill_depth_mm, flipper_length_mm,\n",
        "           body_mass_g, species))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's now clean the data, by discarding rows that contain no feature values at all (`NA` - Not Available values), since they won't be useful in training a model. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Drop rows containing missing values\n",
        "penguins_select <- penguins_select %>%\n",
        "  drop_na()\n",
        "\n",
        "# Proportion of each species in the data\n",
        "penguins_select %>%\n",
        "  count(species)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now that we've dealt with the missing values, let's explore how the features relate to the label by creating some box charts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Load the paletteer package\n",
        "library(paletteer)\n",
        "\n",
        "# Pivot data to a long format\n",
        "penguins_select_long <- penguins_select %>% \n",
        "  pivot_longer(!species, names_to = \"predictors\", values_to = \"values\")\n",
        "\n",
        "# Make box plots\n",
        "theme_set(theme_light())\n",
        "penguins_select_long %>%\n",
        "  ggplot(mapping = aes(x = species, y = values, fill = predictors)) +\n",
        "  geom_boxplot() +\n",
        "  facet_wrap(~predictors, scales = \"free\") +\n",
        "  scale_fill_paletteer_d(\"nbapalettes::supersonics_holiday\") +\n",
        "  theme(legend.position = \"none\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "From the box plots, it looks like species *Adelie* and *Chinstrap* have similar data profiles for bill_depth, flipper_length, and body_mass, but *Chinstraps* tend to have longer bill_length. *Gentoo* tends to have fairly clearly differentiated features from the others; which should help us train a good classification model.\n",
        "\n",
        "### Prepare the data\n",
        "\n",
        "Before training the model, we need to split the data into subsets for training and validation. We'll also apply a *stratification* technique when splitting the data to *maintain the proportion of each label value* in the training and validation datasets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# For reproducibility\n",
        "set.seed(2056)\n",
        "\n",
        "# Split data 70%-30% into training set and test set\n",
        "penguins_split <- penguins_select %>%\n",
        "  initial_split(prop = 0.70, strata = species)\n",
        "\n",
        "# Extract data in each split\n",
        "penguins_train <- training(penguins_split)\n",
        "penguins_test <- testing(penguins_split)\n",
        "\n",
        "# Print the number of observations in each split\n",
        "cat(\"Training cases: \", nrow(penguins_train), \"\\n\",\n",
        "    \"Test cases: \", nrow(penguins_test), sep = \"\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train and evaluate a decision tree model\n",
        "\n",
        "Decision trees take a step-by-step approach to predicting a variable. This type of algorithms starts with all of the data at the root node (the root of the tree) and scans all of the variables for the best one to split on. Let's train and visualize a tree."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Build a decision tree specification\n",
        "tree_spec <- decision_tree(\n",
        "  engine = \"rpart\",\n",
        "  mode = \"classification\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Train a decision tree model\n",
        "tree_mod <- tree_spec %>%\n",
        "  fit(species ~ ., data = penguins_train)\n",
        "\n",
        "# Print model\n",
        "tree_mod"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "library(rattle)\n",
        "library(rpart.plot)\n",
        "library(RColorBrewer)\n",
        "library(rpart)\n",
        "\n",
        "fit <- rpart(species ~ .,\n",
        "             data = penguins_train,\n",
        "             method = \"class\")\n",
        "fancyRpartPlot(fit)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now we can use the trained model to predict the labels for the test features and evaluate performance:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Make predictions for the test set\n",
        "penguins_results <- penguins_test %>% select(species) %>%\n",
        "  bind_cols(tree_mod %>%\n",
        "              predict(new_data = penguins_test)) %>%\n",
        "  bind_cols(tree_mod %>%\n",
        "              predict(new_data = penguins_test, type = \"prob\"))\n",
        "\n",
        "# Print predictions\n",
        "penguins_results %>%\n",
        "  slice_head(n = 10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at the confusion matrix for our model. The confusion matrix shows the intersection of predicted and actual label values for each class. In simpler terms, the diagonal intersections from top-left to bottom-right indicate the number of correct predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "update_geom_defaults(geom = \"tile\", new = list(color = \"black\", alpha = 0.7))\n",
        "# Visualize confusion matrix\n",
        "penguins_results %>%\n",
        "  conf_mat(species, .pred_class) %>%\n",
        "  autoplot(type = \"heatmap\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The confusion matrix is helpful because it gives rise to other metrics that can help you better evaluate the performance of a classification model. Let's go through some of them:\n",
        "\n",
        "* **Precision**: *TP/(TP + FP)*, the proportion of predicted positives that are actually positive (also called [positive predictive value](https://en.wikipedia.org/wiki/Positive_predictive_value)).\n",
        "\n",
        "* **Recall**: *TP/(TP + FN)*, the proportion of positive results out of the number of samples that were actually positive (also known as *sensitivity*).\n",
        "\n",
        "* **Accuracy**: *TP + TN/(TP + TN + FP + FN)*, the proportion of labels that were predicted accurately for a sample."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Combine metrics and evaluate them all at once\n",
        "eval_metrics <- metric_set(ppv, recall, accuracy)\n",
        "eval_metrics(data = penguins_results, truth = species, estimate = .pred_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Train and evaluate a random forest model\n",
        "\n",
        "Ensemble algorithms work by combining multiple base estimators to produce an optimal model. They apply an aggregate function to a collection of base models, which is known as bagging. \n",
        "For example, let's try a random forest model. It applies an averaging function to multiple decision tree models for a better overall model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Build a random forest model specification\n",
        "rf_spec <- rand_forest() %>%\n",
        "  set_engine(\"ranger\", importance = \"impurity\") %>%\n",
        "  set_mode(\"classification\")\n",
        "\n",
        "\n",
        "# Create a workflow that encapsulates a recipe and a model\n",
        "rf_wflow <- recipe(species ~ ., data = penguins_train) %>%\n",
        "  step_normalize(all_numeric_predictors()) %>%\n",
        "  workflow(rf_spec)\n",
        "\n",
        "# Print out workflow\n",
        "rf_wflow\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's now  fit a multiclass classification algorithm to the data to create a random forest model and let's use it to predict the label values on the test dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Fit a model\n",
        "rf_wf_fit <- rf_wflow %>%\n",
        "  fit(data = penguins_train)\n",
        "\n",
        "# Make predictions for the test set\n",
        "penguins_results <- penguins_test %>% select(species) %>%\n",
        "  bind_cols(rf_wf_fit %>%\n",
        "              predict(new_data = penguins_test)) %>%\n",
        "  bind_cols(rf_wf_fit %>%\n",
        "              predict(new_data = penguins_test, type = \"prob\"))\n",
        "\n",
        "# Print predictions\n",
        "penguins_results %>%\n",
        "  slice_head(n = 10)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's look at the confusion matrix for our model. We can notice slightly better results with respect to the decision tree model we previously built."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "update_geom_defaults(geom = \"tile\", new = list(color = \"black\", alpha = 0.7))\n",
        "# Visualize confusion matrix\n",
        "penguins_results %>%\n",
        "  conf_mat(species, .pred_class) %>%\n",
        "  autoplot(type = \"heatmap\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "r"
        }
      },
      "outputs": [],
      "source": [
        "# Combine metrics and evaluate them all at once\n",
        "eval_metrics <- metric_set(ppv, recall, accuracy)\n",
        "eval_metrics(data = penguins_results, truth = species, estimate = .pred_class)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "That went down well! The model did a great job in classifying the penguins. You can further explore machine learning with R through this dedicated [MS Learn learning path](https://docs.microsoft.com/en-us/learn/paths/machine-learning-with-r?WT.mc_id=academic-59300-cacaste)."
      ]
    }
  ],
  "metadata": {
    "anaconda-cloud": "",
    "kernelspec": {
      "display_name": "R",
      "language": "R",
      "name": "ir"
    },
    "language_info": {
      "codemirror_mode": "r",
      "file_extension": ".r",
      "mimetype": "text/x-r-source",
      "name": "R",
      "pygments_lexer": "r",
      "version": "4.1.3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}
